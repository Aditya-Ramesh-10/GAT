{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JZ5SXy1JFtDf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jNcAykXaFtDm",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.sparse.linalg as la\n",
    "import scipy.sparse as sp\n",
    "import scipy\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "%matplotlib inline\n",
    "\n",
    "import scipy.io as sio\n",
    "from utils import process_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "u-DBYiPjFtDv",
    "outputId": "a22132b1-0487-48f8-831d-00c56690951d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2708, 2708)\n",
      "(2708, 1433)\n"
     ]
    }
   ],
   "source": [
    "#learning parameters and path dataset\n",
    "\n",
    "num_total_iter_training = 1000\n",
    "learning_rate = 0.005\n",
    "val_test_interval = 5\n",
    "num_hidden_feat = 8\n",
    "gamma = 5e-4\n",
    "    \n",
    "#cora dataset loading\n",
    "\n",
    "A, X, Y, train_idx, val_idx, test_idx = process_data.load_data(\"cora\")\n",
    "X = process_data.preprocess_features(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kATb3HC-RP67"
   },
   "outputs": [],
   "source": [
    "class GAT_new:\n",
    "    \n",
    "    def frobenius_norm(self, tensor):\n",
    "        square_tensor = tf.square(tensor)\n",
    "        tensor_sum = tf.reduce_sum(square_tensor)\n",
    "        frobenius_norm = tf.sqrt(tensor_sum)\n",
    "        return frobenius_norm    \n",
    "     \n",
    "    def __init__(self, A, X, Y, num_layers, num_hidden_feat, num_heads, learning_rate=5e-2, gamma=1e-3, idx_gpu = '/gpu:0'):\n",
    "        \n",
    "        self.num_hidden_feat = num_hidden_feat\n",
    "        self.num_heads = num_heads\n",
    "        self.learning_rate = learning_rate\n",
    "        self.gamma=gamma\n",
    "        N1 = np.shape(A)[0]\n",
    "        eps = 1e-12\n",
    "        self.l2_reg = 0\n",
    "       \n",
    "        \n",
    "        with tf.Graph().as_default() as g:\n",
    "                self.graph = g\n",
    "                \n",
    "                with tf.device(idx_gpu):\n",
    "\n",
    "                        self.A = tf.constant(A, dtype=tf.float32)\n",
    "                        self.X = tf.constant(X, dtype=tf.float32) \n",
    "                        self.Y = tf.constant(Y, dtype=tf.float32)\n",
    "                        \n",
    "                        #placeholder definition\n",
    "                        self.idx_nodes = tf.placeholder(tf.int32)\n",
    "                        self.keep_prob = tf.placeholder(tf.float32)\n",
    "                        \n",
    "                        self.l_input = tf.nn.dropout(self.X,  self.keep_prob) # N X F0\n",
    "                        \n",
    "                        \n",
    "                        attns = []\n",
    "                        \n",
    "                        for k in range(num_heads[0]):\n",
    "                            self.W0 = tf.get_variable(\"W0_\" + str(k) , shape=[X.shape[1], self.num_hidden_feat], initializer=tf.contrib.layers.xavier_initializer())\n",
    "                            \n",
    "                            self.l1_a0 = tf.get_variable(\"L1_A0_\" + str(k), shape=[1, self.num_hidden_feat], initializer=tf.contrib.layers.xavier_initializer())\n",
    "                            self.l1_a1 = tf.get_variable(\"L1_A1_\" + str(k), shape=[1, self.num_hidden_feat], initializer=tf.contrib.layers.xavier_initializer())\n",
    "                            \n",
    "                            self.x1_new = tf.matmul(self.l_input, self.W0) # N X F0 . F0 X F1 = N X F1 now\n",
    "                            \n",
    "                            \n",
    "                            self.half_0_attn = tf.matmul(self.l1_a0, tf.transpose(self.x1_new)) # 1 X F1 . F1 X N = 1 X N\n",
    "                            self.x1_new = tf.nn.dropout(self.x1_new,  self.keep_prob)\n",
    "                            self.half_1_attn = tf.matmul(self.l1_a1, tf.transpose(self.x1_new)) # 1 X F1 . F1 X N = 1 X N\n",
    "                            \n",
    "                            self.e_half_0 = tf.multiply(self.A, self.half_0_attn) # N X N . N X 1 in broadcast fashion - N X N\n",
    "                            self.e_half_1 = tf.multiply(self.A, tf.transpose(self.half_1_attn)) # multiplies each ROW\n",
    "                            \n",
    "                            self.res = tf.nn.leaky_relu(self.e_half_0 + self.e_half_1, alpha=0.2) # N X N\n",
    "                            \n",
    "                            self.res = tf.math.multiply(tf.exp(self.res), self.A)\n",
    "                            self.res = tf.math.divide(self.res, tf.reduce_sum(self.res, axis = 1, keepdims=True))\n",
    "                            \n",
    "                            \n",
    "                            self.x1_new = tf.nn.dropout(self.x1_new,  self.keep_prob)\n",
    "                            self.res = tf.nn.elu(tf.matmul(self.res, self.x1_new)) # N X N . N X F1 = N X F1\n",
    "                            \n",
    "                            attns.append(self.res)\n",
    "                            \n",
    "                            self.l2_reg += tf.nn.l2_loss(self.W0)\n",
    "                            self.l2_reg += tf.nn.l2_loss(self.l1_a0)\n",
    "                            self.l2_reg += tf.nn.l2_loss(self.l1_a1)\n",
    "                        \n",
    "                        \n",
    "                        self.res = tf.concat(attns, axis=-1) #N X F1 X K\n",
    "                        self.res = tf.reshape(self.res, [N1, self.num_heads[0] * self.num_hidden_feat])\n",
    "\n",
    "                        \n",
    "\n",
    "                        self.W1 = tf.get_variable(\"W1\", shape=[self.num_heads[0] * self.num_hidden_feat, Y.shape[1]], initializer=tf.contrib.layers.xavier_initializer())\n",
    "                        \n",
    "                        \n",
    "                        self.l2_a0 = tf.get_variable(\"L2_A0\", shape=[1, Y.shape[1]], initializer=tf.contrib.layers.xavier_initializer())\n",
    "                        self.l2_a1 = tf.get_variable(\"L2_A1\", shape=[1, Y.shape[1]], initializer=tf.contrib.layers.xavier_initializer())\n",
    "                        \n",
    "                        \n",
    "                        #-------Second Layer------------------------------------\n",
    "                        \n",
    "                        self.l2_input = tf.nn.dropout(self.res,  self.keep_prob)\n",
    "\n",
    "                        self.x2_new = tf.matmul(self.l2_input, self.W1) # N X F0 . F0 X F1 = N X F1 now\n",
    "                        self.half_0_attn_2 = tf.matmul(self.l2_a0, tf.transpose(self.x2_new)) # 1 X F1 . F1 X N = 1 X N\n",
    "                        self.x2_new = tf.nn.dropout(self.x2_new,  self.keep_prob)\n",
    "                        self.half_1_attn_2 = tf.matmul(self.l2_a1, tf.transpose(self.x2_new)) # 1 X F1 . F1 X N = 1 X N\n",
    "                        \n",
    "                        self.e_half_0_2 = tf.multiply(self.A, self.half_0_attn_2) # NXN times 1XN in broadcast fashion - N X N\n",
    "                        self.e_half_1_2 = tf.multiply(self.A, tf.transpose(self.half_1_attn_2))\n",
    "                        \n",
    "                        self.res_2 = tf.nn.leaky_relu(self.e_half_0_2 + self.e_half_1_2, alpha=0.2)\n",
    "                                                  \n",
    "                        self.res_2 = tf.math.multiply(tf.exp(self.res_2), self.A)\n",
    "                        self.res_2 = tf.math.divide(self.res_2, tf.reduce_sum(self.res_2, axis = 1, keepdims=True))\n",
    "\n",
    "                        self.x2_new = tf.nn.dropout(self.x2_new,  self.keep_prob)\n",
    "                        self.logits =tf.matmul(self.res_2, self.x2_new) # N X F1\n",
    "                        \n",
    "                        self.l_out = tf.gather(self.logits, self.idx_nodes)\n",
    "                        self.c_Y = tf.gather(self.Y, self.idx_nodes)\n",
    "                        \n",
    "                        #loss function definition\n",
    "                        self.l2_reg += tf.nn.l2_loss(self.W1)\n",
    "                        self.l2_reg += tf.nn.l2_loss(self.l2_a0)\n",
    "                        self.l2_reg += tf.nn.l2_loss(self.l2_a1)\n",
    "                        self.data_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=self.l_out, labels=self.c_Y)) \n",
    "                        self.loss = self.data_loss + self.gamma*self.l2_reg\n",
    "                        \n",
    "                        #solver definition\n",
    "                        self.optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate)\n",
    "                        self.opt_step = self.optimizer.minimize(self.loss)\n",
    "                        \n",
    "                        #predictions and accuracy extraction\n",
    "                        self.c_predictions = tf.argmax(tf.nn.softmax(self.l_out), 1)\n",
    "                        self.accuracy = tf.contrib.metrics.accuracy(self.c_predictions, tf.argmax(self.c_Y, 1))\n",
    "                        \n",
    "                        #gradients computation\n",
    "                        self.trainable_variables = tf.trainable_variables()\n",
    "                        self.var_grad = tf.gradients(self.loss, tf.trainable_variables())\n",
    "                        self.norm_grad = self.frobenius_norm(tf.concat([tf.reshape(g, [-1]) for g in self.var_grad], 0))\n",
    "                        #self.norm_grad = '0'\n",
    "                        \n",
    "                        #session creation\n",
    "                        config = tf.ConfigProto(allow_soft_placement = True)\n",
    "                        config.gpu_options.allow_growth = True\n",
    "                        self.session = tf.Session(config=config)\n",
    "\n",
    "                        #session initialization\n",
    "                        init = tf.global_variables_initializer()\n",
    "                        self.session.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "vhkHIIIo6eSm",
    "outputId": "41cf7d12-0916-41b7-d5d5-d471770e2440"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adityaramesh/anaconda3/envs/misty/lib/python3.5/site-packages/scipy/sparse/compressed.py:746: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n"
     ]
    }
   ],
   "source": [
    "A_tilde = sp.csr_matrix(A)\n",
    "A_tilde.setdiag(1)\n",
    "A_tilde = A_tilde.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 10713
    },
    "colab_type": "code",
    "id": "zo-wnww26xhs",
    "outputId": "f2a8b7c6-df74-4989-b7d5-0d88ea9954a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-a96e5c87c29c>:33: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /Users/adityaramesh/anaconda3/envs/misty/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-3-a96e5c87c29c>:109: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "WARNING:tensorflow:From /Users/adityaramesh/anaconda3/envs/misty/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "[VAL] epoch = 000, data_cost = 1.95e+00, cost = 1.99e+00, acc = 1.62e-01 (7.80s)\n",
      "[TST] epoch = 000, cost = 1.99e+00, acc = 1.62e-01 (7.89s)\n",
      "[TRN] epoch = 005, cost = 1.95e+00, |grad| = 4.81e-02, acc = 5.71e-01 (1.26s)\n",
      "[VAL] epoch = 005, data_cost = 1.92e+00, cost = 1.95e+00, acc = 7.34e-01 (0.28s)\n",
      "[TST] epoch = 005, cost = 1.95e+00, acc = 7.39e-01 (0.28s)\n",
      "[TRN] epoch = 010, cost = 1.90e+00, |grad| = 5.71e-02, acc = 6.57e-01 (1.25s)\n",
      "[VAL] epoch = 010, data_cost = 1.89e+00, cost = 1.92e+00, acc = 7.80e-01 (0.28s)\n",
      "[TST] epoch = 010, cost = 1.92e+00, acc = 7.85e-01 (0.27s)\n",
      "[TRN] epoch = 015, cost = 1.85e+00, |grad| = 6.22e-02, acc = 7.43e-01 (1.22s)\n",
      "[VAL] epoch = 015, data_cost = 1.86e+00, cost = 1.90e+00, acc = 7.74e-01 (0.28s)\n",
      "[TST] epoch = 015, cost = 1.89e+00, acc = 7.77e-01 (0.28s)\n",
      "[TRN] epoch = 020, cost = 1.81e+00, |grad| = 6.55e-02, acc = 7.71e-01 (1.23s)\n",
      "[VAL] epoch = 020, data_cost = 1.83e+00, cost = 1.87e+00, acc = 7.78e-01 (0.28s)\n",
      "[TST] epoch = 020, cost = 1.86e+00, acc = 7.76e-01 (0.28s)\n",
      "[TRN] epoch = 025, cost = 1.72e+00, |grad| = 8.73e-02, acc = 7.93e-01 (1.23s)\n",
      "[VAL] epoch = 025, data_cost = 1.79e+00, cost = 1.84e+00, acc = 7.78e-01 (0.27s)\n",
      "[TST] epoch = 025, cost = 1.83e+00, acc = 7.78e-01 (0.27s)\n",
      "[TRN] epoch = 030, cost = 1.66e+00, |grad| = 8.82e-02, acc = 7.79e-01 (1.25s)\n",
      "[VAL] epoch = 030, data_cost = 1.74e+00, cost = 1.80e+00, acc = 7.84e-01 (0.28s)\n",
      "[TST] epoch = 030, cost = 1.79e+00, acc = 7.89e-01 (0.27s)\n",
      "[TRN] epoch = 035, cost = 1.60e+00, |grad| = 8.85e-02, acc = 7.29e-01 (1.28s)\n",
      "[VAL] epoch = 035, data_cost = 1.69e+00, cost = 1.76e+00, acc = 7.84e-01 (0.28s)\n",
      "[TST] epoch = 035, cost = 1.74e+00, acc = 7.97e-01 (0.27s)\n",
      "[TRN] epoch = 040, cost = 1.56e+00, |grad| = 9.03e-02, acc = 7.36e-01 (1.24s)\n",
      "[VAL] epoch = 040, data_cost = 1.63e+00, cost = 1.71e+00, acc = 7.90e-01 (0.28s)\n",
      "[TST] epoch = 040, cost = 1.70e+00, acc = 8.03e-01 (0.29s)\n",
      "[TRN] epoch = 045, cost = 1.49e+00, |grad| = 9.92e-02, acc = 7.71e-01 (1.22s)\n",
      "[VAL] epoch = 045, data_cost = 1.57e+00, cost = 1.67e+00, acc = 7.82e-01 (0.28s)\n",
      "[TST] epoch = 045, cost = 1.65e+00, acc = 7.97e-01 (0.28s)\n",
      "[TRN] epoch = 050, cost = 1.47e+00, |grad| = 9.61e-02, acc = 6.93e-01 (1.20s)\n",
      "[VAL] epoch = 050, data_cost = 1.51e+00, cost = 1.63e+00, acc = 7.88e-01 (0.28s)\n",
      "[TST] epoch = 050, cost = 1.60e+00, acc = 7.92e-01 (0.28s)\n",
      "[TRN] epoch = 055, cost = 1.39e+00, |grad| = 9.03e-02, acc = 7.29e-01 (1.20s)\n",
      "[VAL] epoch = 055, data_cost = 1.45e+00, cost = 1.58e+00, acc = 7.90e-01 (0.28s)\n",
      "[TST] epoch = 055, cost = 1.56e+00, acc = 7.93e-01 (0.28s)\n",
      "[TRN] epoch = 060, cost = 1.35e+00, |grad| = 9.84e-02, acc = 7.21e-01 (1.23s)\n",
      "[VAL] epoch = 060, data_cost = 1.39e+00, cost = 1.54e+00, acc = 7.88e-01 (0.28s)\n",
      "[TST] epoch = 060, cost = 1.52e+00, acc = 7.92e-01 (0.27s)\n",
      "[TRN] epoch = 065, cost = 1.26e+00, |grad| = 9.96e-02, acc = 7.71e-01 (1.22s)\n",
      "[VAL] epoch = 065, data_cost = 1.34e+00, cost = 1.50e+00, acc = 7.90e-01 (0.28s)\n",
      "[TST] epoch = 065, cost = 1.47e+00, acc = 7.99e-01 (0.28s)\n",
      "[TRN] epoch = 070, cost = 1.30e+00, |grad| = 1.05e-01, acc = 7.50e-01 (1.22s)\n",
      "[VAL] epoch = 070, data_cost = 1.28e+00, cost = 1.46e+00, acc = 7.90e-01 (0.28s)\n",
      "[TST] epoch = 070, cost = 1.43e+00, acc = 8.07e-01 (0.25s)\n",
      "[TRN] epoch = 075, cost = 1.19e+00, |grad| = 9.50e-02, acc = 7.43e-01 (1.19s)\n",
      "[VAL] epoch = 075, data_cost = 1.24e+00, cost = 1.43e+00, acc = 7.94e-01 (0.28s)\n",
      "[TST] epoch = 075, cost = 1.39e+00, acc = 8.11e-01 (0.28s)\n",
      "[TRN] epoch = 080, cost = 1.17e+00, |grad| = 1.02e-01, acc = 8.07e-01 (1.21s)\n",
      "[VAL] epoch = 080, data_cost = 1.20e+00, cost = 1.40e+00, acc = 7.98e-01 (0.28s)\n",
      "[TST] epoch = 080, cost = 1.36e+00, acc = 8.14e-01 (0.26s)\n",
      "[TRN] epoch = 085, cost = 1.13e+00, |grad| = 9.92e-02, acc = 8.21e-01 (1.20s)\n",
      "[VAL] epoch = 085, data_cost = 1.17e+00, cost = 1.37e+00, acc = 7.96e-01 (0.26s)\n",
      "[TST] epoch = 085, cost = 1.34e+00, acc = 8.09e-01 (0.28s)\n",
      "[TRN] epoch = 090, cost = 1.04e+00, |grad| = 1.07e-01, acc = 7.93e-01 (1.22s)\n",
      "[VAL] epoch = 090, data_cost = 1.14e+00, cost = 1.36e+00, acc = 7.94e-01 (0.27s)\n",
      "[TST] epoch = 090, cost = 1.32e+00, acc = 8.08e-01 (0.27s)\n",
      "[TRN] epoch = 095, cost = 1.18e+00, |grad| = 9.89e-02, acc = 7.14e-01 (1.24s)\n",
      "[VAL] epoch = 095, data_cost = 1.12e+00, cost = 1.34e+00, acc = 8.00e-01 (0.28s)\n",
      "[TST] epoch = 095, cost = 1.30e+00, acc = 8.05e-01 (0.27s)\n",
      "[TRN] epoch = 100, cost = 1.15e+00, |grad| = 1.05e-01, acc = 7.29e-01 (1.18s)\n",
      "[VAL] epoch = 100, data_cost = 1.10e+00, cost = 1.33e+00, acc = 7.98e-01 (0.27s)\n",
      "[TST] epoch = 100, cost = 1.29e+00, acc = 8.00e-01 (0.28s)\n",
      "[TRN] epoch = 105, cost = 1.06e+00, |grad| = 9.45e-02, acc = 7.79e-01 (1.23s)\n",
      "[VAL] epoch = 105, data_cost = 1.07e+00, cost = 1.31e+00, acc = 7.96e-01 (0.27s)\n",
      "[TST] epoch = 105, cost = 1.27e+00, acc = 8.08e-01 (0.27s)\n",
      "[TRN] epoch = 110, cost = 1.05e+00, |grad| = 1.12e-01, acc = 7.93e-01 (1.21s)\n",
      "[VAL] epoch = 110, data_cost = 1.05e+00, cost = 1.29e+00, acc = 7.96e-01 (0.27s)\n",
      "[TST] epoch = 110, cost = 1.25e+00, acc = 8.07e-01 (0.28s)\n",
      "[TRN] epoch = 115, cost = 1.01e+00, |grad| = 1.37e-01, acc = 8.00e-01 (1.26s)\n",
      "[VAL] epoch = 115, data_cost = 1.03e+00, cost = 1.27e+00, acc = 7.96e-01 (0.28s)\n",
      "[TST] epoch = 115, cost = 1.23e+00, acc = 8.10e-01 (0.27s)\n",
      "[TRN] epoch = 120, cost = 9.83e-01, |grad| = 1.07e-01, acc = 8.43e-01 (1.23s)\n",
      "[VAL] epoch = 120, data_cost = 1.01e+00, cost = 1.26e+00, acc = 7.94e-01 (0.29s)\n",
      "[TST] epoch = 120, cost = 1.22e+00, acc = 8.08e-01 (0.29s)\n",
      "[TRN] epoch = 125, cost = 1.07e+00, |grad| = 1.45e-01, acc = 7.57e-01 (1.24s)\n",
      "[VAL] epoch = 125, data_cost = 9.96e-01, cost = 1.25e+00, acc = 7.96e-01 (0.26s)\n",
      "[TST] epoch = 125, cost = 1.20e+00, acc = 8.11e-01 (0.26s)\n",
      "[TRN] epoch = 130, cost = 9.84e-01, |grad| = 8.70e-02, acc = 8.07e-01 (1.26s)\n",
      "[VAL] epoch = 130, data_cost = 9.81e-01, cost = 1.23e+00, acc = 7.96e-01 (0.27s)\n",
      "[TST] epoch = 130, cost = 1.19e+00, acc = 8.12e-01 (0.27s)\n",
      "[TRN] epoch = 135, cost = 9.73e-01, |grad| = 1.10e-01, acc = 8.50e-01 (1.19s)\n",
      "[VAL] epoch = 135, data_cost = 9.71e-01, cost = 1.23e+00, acc = 7.96e-01 (0.26s)\n",
      "[TST] epoch = 135, cost = 1.18e+00, acc = 8.11e-01 (0.26s)\n",
      "[TRN] epoch = 140, cost = 1.01e+00, |grad| = 1.04e-01, acc = 7.64e-01 (1.20s)\n",
      "[VAL] epoch = 140, data_cost = 9.64e-01, cost = 1.22e+00, acc = 7.92e-01 (0.27s)\n",
      "[TST] epoch = 140, cost = 1.18e+00, acc = 8.06e-01 (0.26s)\n",
      "[TRN] epoch = 145, cost = 9.74e-01, |grad| = 1.02e-01, acc = 7.93e-01 (1.19s)\n",
      "[VAL] epoch = 145, data_cost = 9.62e-01, cost = 1.22e+00, acc = 7.96e-01 (0.28s)\n",
      "[TST] epoch = 145, cost = 1.18e+00, acc = 8.02e-01 (0.26s)\n",
      "[TRN] epoch = 150, cost = 9.30e-01, |grad| = 1.05e-01, acc = 7.93e-01 (1.25s)\n",
      "[VAL] epoch = 150, data_cost = 9.55e-01, cost = 1.22e+00, acc = 7.94e-01 (0.27s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TST] epoch = 150, cost = 1.17e+00, acc = 7.99e-01 (0.28s)\n",
      "[TRN] epoch = 155, cost = 9.40e-01, |grad| = 9.47e-02, acc = 8.21e-01 (1.21s)\n",
      "[VAL] epoch = 155, data_cost = 9.45e-01, cost = 1.21e+00, acc = 7.94e-01 (0.26s)\n",
      "[TST] epoch = 155, cost = 1.16e+00, acc = 8.04e-01 (0.27s)\n",
      "[TRN] epoch = 160, cost = 1.03e+00, |grad| = 1.03e-01, acc = 7.93e-01 (1.24s)\n",
      "[VAL] epoch = 160, data_cost = 9.37e-01, cost = 1.20e+00, acc = 7.92e-01 (0.27s)\n",
      "[TST] epoch = 160, cost = 1.16e+00, acc = 8.04e-01 (0.28s)\n",
      "[TRN] epoch = 165, cost = 9.84e-01, |grad| = 9.32e-02, acc = 8.29e-01 (1.21s)\n",
      "[VAL] epoch = 165, data_cost = 9.26e-01, cost = 1.19e+00, acc = 7.92e-01 (0.28s)\n",
      "[TST] epoch = 165, cost = 1.15e+00, acc = 8.08e-01 (0.28s)\n",
      "[TRN] epoch = 170, cost = 9.85e-01, |grad| = 8.86e-02, acc = 7.93e-01 (1.17s)\n",
      "[VAL] epoch = 170, data_cost = 9.18e-01, cost = 1.19e+00, acc = 7.92e-01 (0.27s)\n",
      "[TST] epoch = 170, cost = 1.14e+00, acc = 8.07e-01 (0.28s)\n",
      "[TRN] epoch = 175, cost = 9.46e-01, |grad| = 8.36e-02, acc = 8.36e-01 (1.22s)\n",
      "[VAL] epoch = 175, data_cost = 9.09e-01, cost = 1.18e+00, acc = 7.92e-01 (0.26s)\n",
      "[TST] epoch = 175, cost = 1.14e+00, acc = 8.08e-01 (0.28s)\n",
      "[TRN] epoch = 180, cost = 1.02e+00, |grad| = 1.10e-01, acc = 7.79e-01 (1.23s)\n",
      "[VAL] epoch = 180, data_cost = 9.00e-01, cost = 1.17e+00, acc = 7.96e-01 (0.27s)\n",
      "[TST] epoch = 180, cost = 1.13e+00, acc = 8.09e-01 (0.26s)\n",
      "[TRN] epoch = 185, cost = 8.97e-01, |grad| = 1.01e-01, acc = 8.29e-01 (1.22s)\n",
      "[VAL] epoch = 185, data_cost = 8.88e-01, cost = 1.16e+00, acc = 7.96e-01 (0.26s)\n",
      "[TST] epoch = 185, cost = 1.12e+00, acc = 8.11e-01 (0.27s)\n",
      "[TRN] epoch = 190, cost = 9.00e-01, |grad| = 1.48e-01, acc = 8.14e-01 (1.20s)\n",
      "[VAL] epoch = 190, data_cost = 8.78e-01, cost = 1.15e+00, acc = 7.96e-01 (0.28s)\n",
      "[TST] epoch = 190, cost = 1.11e+00, acc = 8.14e-01 (0.28s)\n",
      "[TRN] epoch = 195, cost = 8.97e-01, |grad| = 8.59e-02, acc = 7.86e-01 (1.23s)\n",
      "[VAL] epoch = 195, data_cost = 8.71e-01, cost = 1.15e+00, acc = 7.96e-01 (0.28s)\n",
      "[TST] epoch = 195, cost = 1.11e+00, acc = 8.15e-01 (0.28s)\n",
      "[TRN] epoch = 200, cost = 9.06e-01, |grad| = 1.07e-01, acc = 8.21e-01 (1.22s)\n",
      "[VAL] epoch = 200, data_cost = 8.63e-01, cost = 1.14e+00, acc = 7.96e-01 (0.27s)\n",
      "[TST] epoch = 200, cost = 1.10e+00, acc = 8.15e-01 (0.28s)\n",
      "[TRN] epoch = 205, cost = 1.05e+00, |grad| = 9.13e-02, acc = 7.71e-01 (1.22s)\n",
      "[VAL] epoch = 205, data_cost = 8.50e-01, cost = 1.13e+00, acc = 7.98e-01 (0.27s)\n",
      "[TST] epoch = 205, cost = 1.09e+00, acc = 8.15e-01 (0.26s)\n",
      "[TRN] epoch = 210, cost = 1.01e+00, |grad| = 1.14e-01, acc = 7.79e-01 (1.28s)\n",
      "[VAL] epoch = 210, data_cost = 8.44e-01, cost = 1.13e+00, acc = 7.98e-01 (0.27s)\n",
      "[TST] epoch = 210, cost = 1.09e+00, acc = 8.20e-01 (0.26s)\n",
      "[TRN] epoch = 215, cost = 9.30e-01, |grad| = 9.37e-02, acc = 8.21e-01 (1.22s)\n",
      "[VAL] epoch = 215, data_cost = 8.39e-01, cost = 1.12e+00, acc = 7.98e-01 (0.28s)\n",
      "[TST] epoch = 215, cost = 1.08e+00, acc = 8.17e-01 (0.28s)\n",
      "[TRN] epoch = 220, cost = 9.90e-01, |grad| = 1.07e-01, acc = 8.00e-01 (1.27s)\n",
      "[VAL] epoch = 220, data_cost = 8.33e-01, cost = 1.12e+00, acc = 7.98e-01 (0.28s)\n",
      "[TST] epoch = 220, cost = 1.08e+00, acc = 8.19e-01 (0.28s)\n",
      "[TRN] epoch = 225, cost = 9.14e-01, |grad| = 8.44e-02, acc = 8.36e-01 (1.20s)\n",
      "[VAL] epoch = 225, data_cost = 8.29e-01, cost = 1.12e+00, acc = 7.96e-01 (0.26s)\n",
      "[TST] epoch = 225, cost = 1.08e+00, acc = 8.18e-01 (0.28s)\n",
      "[TRN] epoch = 230, cost = 8.76e-01, |grad| = 9.49e-02, acc = 8.50e-01 (1.25s)\n",
      "[VAL] epoch = 230, data_cost = 8.24e-01, cost = 1.12e+00, acc = 7.96e-01 (0.27s)\n",
      "[TST] epoch = 230, cost = 1.07e+00, acc = 8.16e-01 (0.27s)\n",
      "[TRN] epoch = 235, cost = 7.90e-01, |grad| = 7.84e-02, acc = 8.93e-01 (1.21s)\n",
      "[VAL] epoch = 235, data_cost = 8.20e-01, cost = 1.11e+00, acc = 7.98e-01 (0.28s)\n",
      "[TST] epoch = 235, cost = 1.07e+00, acc = 8.17e-01 (0.28s)\n",
      "[TRN] epoch = 240, cost = 8.67e-01, |grad| = 1.01e-01, acc = 8.50e-01 (1.29s)\n",
      "[VAL] epoch = 240, data_cost = 8.12e-01, cost = 1.11e+00, acc = 7.96e-01 (0.29s)\n",
      "[TST] epoch = 240, cost = 1.07e+00, acc = 8.18e-01 (0.28s)\n",
      "[TRN] epoch = 245, cost = 7.68e-01, |grad| = 7.33e-02, acc = 8.64e-01 (1.31s)\n",
      "[VAL] epoch = 245, data_cost = 8.07e-01, cost = 1.10e+00, acc = 7.98e-01 (0.28s)\n",
      "[TST] epoch = 245, cost = 1.06e+00, acc = 8.20e-01 (0.28s)\n",
      "[TRN] epoch = 250, cost = 8.72e-01, |grad| = 9.42e-02, acc = 8.07e-01 (1.25s)\n",
      "[VAL] epoch = 250, data_cost = 8.01e-01, cost = 1.10e+00, acc = 7.96e-01 (0.27s)\n",
      "[TST] epoch = 250, cost = 1.06e+00, acc = 8.23e-01 (0.28s)\n",
      "[TRN] epoch = 255, cost = 8.05e-01, |grad| = 1.19e-01, acc = 8.71e-01 (1.20s)\n",
      "[VAL] epoch = 255, data_cost = 7.91e-01, cost = 1.09e+00, acc = 7.98e-01 (0.26s)\n",
      "[TST] epoch = 255, cost = 1.05e+00, acc = 8.25e-01 (0.26s)\n",
      "[TRN] epoch = 260, cost = 7.62e-01, |grad| = 7.24e-02, acc = 8.86e-01 (1.21s)\n",
      "[VAL] epoch = 260, data_cost = 7.87e-01, cost = 1.09e+00, acc = 7.98e-01 (0.27s)\n",
      "[TST] epoch = 260, cost = 1.05e+00, acc = 8.25e-01 (0.28s)\n",
      "[TRN] epoch = 265, cost = 8.22e-01, |grad| = 9.32e-02, acc = 8.43e-01 (1.22s)\n",
      "[VAL] epoch = 265, data_cost = 7.91e-01, cost = 1.09e+00, acc = 7.94e-01 (0.29s)\n",
      "[TST] epoch = 265, cost = 1.05e+00, acc = 8.22e-01 (0.27s)\n",
      "[TRN] epoch = 270, cost = 8.50e-01, |grad| = 8.01e-02, acc = 8.86e-01 (1.26s)\n",
      "[VAL] epoch = 270, data_cost = 8.00e-01, cost = 1.10e+00, acc = 7.96e-01 (0.27s)\n",
      "[TST] epoch = 270, cost = 1.06e+00, acc = 8.22e-01 (0.28s)\n",
      "[TRN] epoch = 275, cost = 8.58e-01, |grad| = 8.40e-02, acc = 8.21e-01 (1.27s)\n",
      "[VAL] epoch = 275, data_cost = 8.01e-01, cost = 1.10e+00, acc = 7.92e-01 (0.26s)\n",
      "[TST] epoch = 275, cost = 1.06e+00, acc = 8.21e-01 (0.27s)\n",
      "[TRN] epoch = 280, cost = 8.29e-01, |grad| = 8.19e-02, acc = 8.50e-01 (1.25s)\n",
      "[VAL] epoch = 280, data_cost = 7.93e-01, cost = 1.10e+00, acc = 7.94e-01 (0.28s)\n",
      "[TST] epoch = 280, cost = 1.06e+00, acc = 8.19e-01 (0.28s)\n",
      "[TRN] epoch = 285, cost = 9.21e-01, |grad| = 1.06e-01, acc = 8.29e-01 (1.31s)\n",
      "[VAL] epoch = 285, data_cost = 7.85e-01, cost = 1.09e+00, acc = 7.98e-01 (0.28s)\n",
      "[TST] epoch = 285, cost = 1.05e+00, acc = 8.21e-01 (0.28s)\n",
      "[TRN] epoch = 290, cost = 8.82e-01, |grad| = 8.02e-02, acc = 8.14e-01 (1.27s)\n",
      "[VAL] epoch = 290, data_cost = 7.79e-01, cost = 1.09e+00, acc = 8.00e-01 (0.28s)\n",
      "[TST] epoch = 290, cost = 1.05e+00, acc = 8.19e-01 (0.27s)\n",
      "[TRN] epoch = 295, cost = 9.71e-01, |grad| = 9.70e-02, acc = 7.71e-01 (1.29s)\n",
      "[VAL] epoch = 295, data_cost = 7.75e-01, cost = 1.08e+00, acc = 8.00e-01 (0.27s)\n",
      "[TST] epoch = 295, cost = 1.05e+00, acc = 8.19e-01 (0.29s)\n",
      "[TRN] epoch = 300, cost = 8.82e-01, |grad| = 9.66e-02, acc = 8.29e-01 (1.30s)\n",
      "[VAL] epoch = 300, data_cost = 7.69e-01, cost = 1.08e+00, acc = 8.00e-01 (0.29s)\n",
      "[TST] epoch = 300, cost = 1.04e+00, acc = 8.26e-01 (0.28s)\n",
      "[TRN] epoch = 305, cost = 9.80e-01, |grad| = 1.13e-01, acc = 7.57e-01 (1.29s)\n",
      "[VAL] epoch = 305, data_cost = 7.67e-01, cost = 1.08e+00, acc = 8.00e-01 (0.27s)\n",
      "[TST] epoch = 305, cost = 1.04e+00, acc = 8.25e-01 (0.29s)\n",
      "[TRN] epoch = 310, cost = 8.84e-01, |grad| = 8.34e-02, acc = 8.21e-01 (1.29s)\n",
      "[VAL] epoch = 310, data_cost = 7.68e-01, cost = 1.08e+00, acc = 7.96e-01 (0.27s)\n",
      "[TST] epoch = 310, cost = 1.04e+00, acc = 8.24e-01 (0.28s)\n",
      "[TRN] epoch = 315, cost = 9.79e-01, |grad| = 9.41e-02, acc = 7.79e-01 (1.30s)\n",
      "[VAL] epoch = 315, data_cost = 7.67e-01, cost = 1.08e+00, acc = 8.00e-01 (0.28s)\n",
      "[TST] epoch = 315, cost = 1.04e+00, acc = 8.23e-01 (0.29s)\n",
      "[TRN] epoch = 320, cost = 8.33e-01, |grad| = 7.70e-02, acc = 8.71e-01 (1.30s)\n",
      "[VAL] epoch = 320, data_cost = 7.65e-01, cost = 1.08e+00, acc = 8.02e-01 (0.28s)\n",
      "[TST] epoch = 320, cost = 1.04e+00, acc = 8.24e-01 (0.28s)\n",
      "[TRN] epoch = 325, cost = 7.96e-01, |grad| = 9.86e-02, acc = 8.43e-01 (1.27s)\n",
      "[VAL] epoch = 325, data_cost = 7.63e-01, cost = 1.08e+00, acc = 7.96e-01 (0.27s)\n",
      "[TST] epoch = 325, cost = 1.04e+00, acc = 8.20e-01 (0.28s)\n",
      "[TRN] epoch = 330, cost = 9.06e-01, |grad| = 1.07e-01, acc = 8.14e-01 (1.27s)\n",
      "[VAL] epoch = 330, data_cost = 7.62e-01, cost = 1.08e+00, acc = 7.96e-01 (0.29s)\n",
      "[TST] epoch = 330, cost = 1.04e+00, acc = 8.20e-01 (0.28s)\n",
      "[TRN] epoch = 335, cost = 8.71e-01, |grad| = 1.27e-01, acc = 8.29e-01 (1.27s)\n",
      "[VAL] epoch = 335, data_cost = 7.58e-01, cost = 1.07e+00, acc = 7.96e-01 (0.26s)\n",
      "[TST] epoch = 335, cost = 1.04e+00, acc = 8.19e-01 (0.27s)\n",
      "[TRN] epoch = 340, cost = 8.18e-01, |grad| = 8.83e-02, acc = 8.64e-01 (1.28s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] epoch = 340, data_cost = 7.50e-01, cost = 1.07e+00, acc = 8.00e-01 (0.28s)\n",
      "[TST] epoch = 340, cost = 1.03e+00, acc = 8.26e-01 (0.26s)\n",
      "[TRN] epoch = 345, cost = 8.56e-01, |grad| = 1.04e-01, acc = 8.21e-01 (1.24s)\n",
      "[VAL] epoch = 345, data_cost = 7.46e-01, cost = 1.06e+00, acc = 7.98e-01 (0.26s)\n",
      "[TST] epoch = 345, cost = 1.03e+00, acc = 8.26e-01 (0.27s)\n",
      "[TRN] epoch = 350, cost = 8.63e-01, |grad| = 8.28e-02, acc = 8.57e-01 (1.31s)\n",
      "[VAL] epoch = 350, data_cost = 7.43e-01, cost = 1.06e+00, acc = 8.02e-01 (0.28s)\n",
      "[TST] epoch = 350, cost = 1.03e+00, acc = 8.26e-01 (0.29s)\n",
      "[TRN] epoch = 355, cost = 7.89e-01, |grad| = 7.85e-02, acc = 8.86e-01 (1.29s)\n",
      "[VAL] epoch = 355, data_cost = 7.48e-01, cost = 1.07e+00, acc = 8.08e-01 (0.29s)\n",
      "[TST] epoch = 355, cost = 1.03e+00, acc = 8.24e-01 (0.29s)\n",
      "[TRN] epoch = 360, cost = 8.82e-01, |grad| = 7.85e-02, acc = 8.07e-01 (1.27s)\n",
      "[VAL] epoch = 360, data_cost = 7.47e-01, cost = 1.07e+00, acc = 8.06e-01 (0.30s)\n",
      "[TST] epoch = 360, cost = 1.03e+00, acc = 8.25e-01 (0.27s)\n",
      "[TRN] epoch = 365, cost = 9.38e-01, |grad| = 1.28e-01, acc = 8.07e-01 (1.27s)\n",
      "[VAL] epoch = 365, data_cost = 7.46e-01, cost = 1.07e+00, acc = 8.04e-01 (0.27s)\n",
      "[TST] epoch = 365, cost = 1.03e+00, acc = 8.26e-01 (0.26s)\n",
      "[TRN] epoch = 370, cost = 7.92e-01, |grad| = 9.47e-02, acc = 8.57e-01 (1.30s)\n",
      "[VAL] epoch = 370, data_cost = 7.42e-01, cost = 1.06e+00, acc = 8.06e-01 (0.29s)\n",
      "[TST] epoch = 370, cost = 1.03e+00, acc = 8.24e-01 (0.28s)\n",
      "[TRN] epoch = 375, cost = 7.69e-01, |grad| = 8.21e-02, acc = 8.36e-01 (1.33s)\n",
      "[VAL] epoch = 375, data_cost = 7.39e-01, cost = 1.06e+00, acc = 8.06e-01 (0.28s)\n",
      "[TST] epoch = 375, cost = 1.02e+00, acc = 8.26e-01 (0.26s)\n",
      "[TRN] epoch = 380, cost = 8.48e-01, |grad| = 9.40e-02, acc = 8.57e-01 (1.29s)\n",
      "[VAL] epoch = 380, data_cost = 7.37e-01, cost = 1.06e+00, acc = 8.06e-01 (0.28s)\n",
      "[TST] epoch = 380, cost = 1.02e+00, acc = 8.26e-01 (0.29s)\n",
      "[TRN] epoch = 385, cost = 8.22e-01, |grad| = 9.32e-02, acc = 8.71e-01 (1.24s)\n",
      "[VAL] epoch = 385, data_cost = 7.35e-01, cost = 1.06e+00, acc = 8.02e-01 (0.28s)\n",
      "[TST] epoch = 385, cost = 1.02e+00, acc = 8.24e-01 (0.26s)\n",
      "[TRN] epoch = 390, cost = 7.80e-01, |grad| = 9.10e-02, acc = 9.07e-01 (1.27s)\n",
      "[VAL] epoch = 390, data_cost = 7.38e-01, cost = 1.07e+00, acc = 8.00e-01 (0.28s)\n",
      "[TST] epoch = 390, cost = 1.03e+00, acc = 8.22e-01 (0.26s)\n",
      "[TRN] epoch = 395, cost = 8.21e-01, |grad| = 7.13e-02, acc = 8.50e-01 (1.28s)\n",
      "[VAL] epoch = 395, data_cost = 7.41e-01, cost = 1.07e+00, acc = 8.00e-01 (0.27s)\n",
      "[TST] epoch = 395, cost = 1.03e+00, acc = 8.19e-01 (0.29s)\n",
      "[TRN] epoch = 400, cost = 8.54e-01, |grad| = 8.09e-02, acc = 8.50e-01 (1.25s)\n",
      "[VAL] epoch = 400, data_cost = 7.40e-01, cost = 1.07e+00, acc = 8.00e-01 (0.26s)\n",
      "[TST] epoch = 400, cost = 1.03e+00, acc = 8.21e-01 (0.27s)\n",
      "[TRN] epoch = 405, cost = 9.14e-01, |grad| = 1.11e-01, acc = 8.43e-01 (1.26s)\n",
      "[VAL] epoch = 405, data_cost = 7.38e-01, cost = 1.07e+00, acc = 7.96e-01 (0.27s)\n",
      "[TST] epoch = 405, cost = 1.03e+00, acc = 8.24e-01 (0.27s)\n",
      "[TRN] epoch = 410, cost = 8.11e-01, |grad| = 8.38e-02, acc = 8.43e-01 (1.27s)\n",
      "[VAL] epoch = 410, data_cost = 7.37e-01, cost = 1.07e+00, acc = 8.00e-01 (0.27s)\n",
      "[TST] epoch = 410, cost = 1.03e+00, acc = 8.24e-01 (0.28s)\n",
      "[TRN] epoch = 415, cost = 7.25e-01, |grad| = 7.33e-02, acc = 8.71e-01 (1.31s)\n",
      "[VAL] epoch = 415, data_cost = 7.38e-01, cost = 1.07e+00, acc = 7.98e-01 (0.28s)\n",
      "[TST] epoch = 415, cost = 1.03e+00, acc = 8.22e-01 (0.27s)\n",
      "[TRN] epoch = 420, cost = 8.41e-01, |grad| = 8.48e-02, acc = 9.00e-01 (1.33s)\n",
      "[VAL] epoch = 420, data_cost = 7.36e-01, cost = 1.07e+00, acc = 7.98e-01 (0.28s)\n",
      "[TST] epoch = 420, cost = 1.03e+00, acc = 8.22e-01 (0.27s)\n",
      "[TRN] epoch = 425, cost = 8.24e-01, |grad| = 1.07e-01, acc = 8.36e-01 (1.32s)\n",
      "[VAL] epoch = 425, data_cost = 7.30e-01, cost = 1.06e+00, acc = 7.98e-01 (0.28s)\n",
      "[TST] epoch = 425, cost = 1.02e+00, acc = 8.22e-01 (0.28s)\n",
      "[TRN] epoch = 430, cost = 8.84e-01, |grad| = 9.37e-02, acc = 8.29e-01 (1.24s)\n",
      "[VAL] epoch = 430, data_cost = 7.31e-01, cost = 1.06e+00, acc = 8.00e-01 (0.28s)\n",
      "[TST] epoch = 430, cost = 1.03e+00, acc = 8.23e-01 (0.28s)\n",
      "[TRN] epoch = 435, cost = 8.20e-01, |grad| = 1.20e-01, acc = 8.71e-01 (1.28s)\n",
      "[VAL] epoch = 435, data_cost = 7.36e-01, cost = 1.07e+00, acc = 7.96e-01 (0.28s)\n",
      "[TST] epoch = 435, cost = 1.03e+00, acc = 8.21e-01 (0.27s)\n",
      "[TRN] epoch = 440, cost = 8.98e-01, |grad| = 1.21e-01, acc = 8.29e-01 (1.30s)\n",
      "[VAL] epoch = 440, data_cost = 7.35e-01, cost = 1.07e+00, acc = 7.96e-01 (0.28s)\n",
      "[TST] epoch = 440, cost = 1.03e+00, acc = 8.23e-01 (0.28s)\n",
      "[TRN] epoch = 445, cost = 8.56e-01, |grad| = 9.47e-02, acc = 8.43e-01 (1.29s)\n",
      "[VAL] epoch = 445, data_cost = 7.29e-01, cost = 1.06e+00, acc = 7.98e-01 (0.28s)\n",
      "[TST] epoch = 445, cost = 1.03e+00, acc = 8.24e-01 (0.28s)\n",
      "[TRN] epoch = 450, cost = 9.55e-01, |grad| = 1.10e-01, acc = 8.36e-01 (1.32s)\n",
      "[VAL] epoch = 450, data_cost = 7.27e-01, cost = 1.06e+00, acc = 8.00e-01 (0.29s)\n",
      "[TST] epoch = 450, cost = 1.02e+00, acc = 8.27e-01 (0.28s)\n",
      "[TRN] epoch = 455, cost = 8.83e-01, |grad| = 1.05e-01, acc = 8.43e-01 (1.26s)\n",
      "[VAL] epoch = 455, data_cost = 7.26e-01, cost = 1.06e+00, acc = 8.02e-01 (0.27s)\n",
      "[TST] epoch = 455, cost = 1.02e+00, acc = 8.29e-01 (0.27s)\n",
      "[TRN] epoch = 460, cost = 7.67e-01, |grad| = 1.11e-01, acc = 8.64e-01 (1.31s)\n",
      "[VAL] epoch = 460, data_cost = 7.26e-01, cost = 1.06e+00, acc = 8.00e-01 (0.28s)\n",
      "[TST] epoch = 460, cost = 1.02e+00, acc = 8.30e-01 (0.27s)\n",
      "[TRN] epoch = 465, cost = 8.17e-01, |grad| = 8.82e-02, acc = 8.36e-01 (1.29s)\n",
      "[VAL] epoch = 465, data_cost = 7.29e-01, cost = 1.07e+00, acc = 8.02e-01 (0.29s)\n",
      "[TST] epoch = 465, cost = 1.03e+00, acc = 8.28e-01 (0.28s)\n",
      "[TRN] epoch = 470, cost = 8.39e-01, |grad| = 1.06e-01, acc = 8.43e-01 (1.28s)\n",
      "[VAL] epoch = 470, data_cost = 7.32e-01, cost = 1.07e+00, acc = 7.98e-01 (0.27s)\n",
      "[TST] epoch = 470, cost = 1.03e+00, acc = 8.25e-01 (0.28s)\n",
      "[TRN] epoch = 475, cost = 7.92e-01, |grad| = 8.82e-02, acc = 8.79e-01 (1.28s)\n",
      "[VAL] epoch = 475, data_cost = 7.32e-01, cost = 1.07e+00, acc = 8.02e-01 (0.27s)\n",
      "[TST] epoch = 475, cost = 1.03e+00, acc = 8.22e-01 (0.27s)\n",
      "[TRN] epoch = 480, cost = 7.48e-01, |grad| = 7.35e-02, acc = 8.79e-01 (1.22s)\n",
      "[VAL] epoch = 480, data_cost = 7.28e-01, cost = 1.07e+00, acc = 8.04e-01 (0.28s)\n",
      "[TST] epoch = 480, cost = 1.03e+00, acc = 8.26e-01 (0.29s)\n",
      "[TRN] epoch = 485, cost = 8.48e-01, |grad| = 1.08e-01, acc = 8.29e-01 (1.24s)\n",
      "[VAL] epoch = 485, data_cost = 7.27e-01, cost = 1.06e+00, acc = 8.04e-01 (0.28s)\n",
      "[TST] epoch = 485, cost = 1.02e+00, acc = 8.31e-01 (0.26s)\n",
      "[TRN] epoch = 490, cost = 8.69e-01, |grad| = 9.72e-02, acc = 8.00e-01 (1.29s)\n",
      "[VAL] epoch = 490, data_cost = 7.27e-01, cost = 1.07e+00, acc = 7.96e-01 (0.27s)\n",
      "[TST] epoch = 490, cost = 1.03e+00, acc = 8.27e-01 (0.28s)\n",
      "[TRN] epoch = 495, cost = 8.30e-01, |grad| = 9.81e-02, acc = 8.57e-01 (1.27s)\n",
      "[VAL] epoch = 495, data_cost = 7.28e-01, cost = 1.07e+00, acc = 7.98e-01 (0.27s)\n",
      "[TST] epoch = 495, cost = 1.03e+00, acc = 8.22e-01 (0.28s)\n",
      "[TRN] epoch = 500, cost = 7.37e-01, |grad| = 1.01e-01, acc = 8.93e-01 (1.24s)\n",
      "[VAL] epoch = 500, data_cost = 7.27e-01, cost = 1.07e+00, acc = 8.00e-01 (0.28s)\n",
      "[TST] epoch = 500, cost = 1.03e+00, acc = 8.20e-01 (0.26s)\n",
      "[TRN] epoch = 505, cost = 9.47e-01, |grad| = 9.40e-02, acc = 7.93e-01 (1.28s)\n",
      "[VAL] epoch = 505, data_cost = 7.25e-01, cost = 1.07e+00, acc = 7.96e-01 (0.27s)\n",
      "[TST] epoch = 505, cost = 1.03e+00, acc = 8.22e-01 (0.26s)\n",
      "[TRN] epoch = 510, cost = 8.33e-01, |grad| = 8.62e-02, acc = 8.71e-01 (1.26s)\n",
      "[VAL] epoch = 510, data_cost = 7.17e-01, cost = 1.06e+00, acc = 7.98e-01 (0.27s)\n",
      "[TST] epoch = 510, cost = 1.02e+00, acc = 8.25e-01 (0.28s)\n",
      "[TRN] epoch = 515, cost = 8.34e-01, |grad| = 1.04e-01, acc = 8.43e-01 (1.29s)\n",
      "[VAL] epoch = 515, data_cost = 7.11e-01, cost = 1.05e+00, acc = 7.98e-01 (0.28s)\n",
      "[TST] epoch = 515, cost = 1.02e+00, acc = 8.26e-01 (0.28s)\n",
      "[TRN] epoch = 520, cost = 7.66e-01, |grad| = 8.51e-02, acc = 8.64e-01 (1.24s)\n",
      "[VAL] epoch = 520, data_cost = 7.09e-01, cost = 1.05e+00, acc = 8.02e-01 (0.27s)\n",
      "[TST] epoch = 520, cost = 1.02e+00, acc = 8.27e-01 (0.28s)\n",
      "[TRN] epoch = 525, cost = 8.00e-01, |grad| = 8.48e-02, acc = 9.07e-01 (1.27s)\n",
      "[VAL] epoch = 525, data_cost = 7.11e-01, cost = 1.06e+00, acc = 8.06e-01 (0.27s)\n",
      "[TST] epoch = 525, cost = 1.02e+00, acc = 8.27e-01 (0.27s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRN] epoch = 530, cost = 8.13e-01, |grad| = 8.89e-02, acc = 8.64e-01 (1.28s)\n",
      "[VAL] epoch = 530, data_cost = 7.13e-01, cost = 1.06e+00, acc = 8.02e-01 (0.27s)\n",
      "[TST] epoch = 530, cost = 1.02e+00, acc = 8.27e-01 (0.27s)\n",
      "[TRN] epoch = 535, cost = 8.71e-01, |grad| = 1.68e-01, acc = 8.64e-01 (1.24s)\n",
      "[VAL] epoch = 535, data_cost = 7.14e-01, cost = 1.06e+00, acc = 8.06e-01 (0.27s)\n",
      "[TST] epoch = 535, cost = 1.02e+00, acc = 8.26e-01 (0.27s)\n",
      "[TRN] epoch = 540, cost = 7.16e-01, |grad| = 7.16e-02, acc = 9.14e-01 (1.29s)\n",
      "[VAL] epoch = 540, data_cost = 7.16e-01, cost = 1.06e+00, acc = 8.02e-01 (0.28s)\n",
      "[TST] epoch = 540, cost = 1.02e+00, acc = 8.28e-01 (0.28s)\n",
      "[TRN] epoch = 545, cost = 8.77e-01, |grad| = 8.79e-02, acc = 8.36e-01 (1.27s)\n",
      "[VAL] epoch = 545, data_cost = 7.18e-01, cost = 1.06e+00, acc = 8.00e-01 (0.27s)\n",
      "[TST] epoch = 545, cost = 1.02e+00, acc = 8.27e-01 (0.26s)\n",
      "[TRN] epoch = 550, cost = 7.68e-01, |grad| = 7.96e-02, acc = 8.93e-01 (1.20s)\n",
      "[VAL] epoch = 550, data_cost = 7.19e-01, cost = 1.06e+00, acc = 7.98e-01 (0.27s)\n",
      "[TST] epoch = 550, cost = 1.02e+00, acc = 8.25e-01 (0.28s)\n",
      "[TRN] epoch = 555, cost = 8.46e-01, |grad| = 9.12e-02, acc = 8.79e-01 (1.23s)\n",
      "[VAL] epoch = 555, data_cost = 7.18e-01, cost = 1.06e+00, acc = 8.02e-01 (0.26s)\n",
      "[TST] epoch = 555, cost = 1.02e+00, acc = 8.27e-01 (0.27s)\n",
      "[TRN] epoch = 560, cost = 8.62e-01, |grad| = 1.04e-01, acc = 8.07e-01 (1.23s)\n",
      "[VAL] epoch = 560, data_cost = 7.18e-01, cost = 1.06e+00, acc = 8.00e-01 (0.26s)\n",
      "[TST] epoch = 560, cost = 1.02e+00, acc = 8.25e-01 (0.26s)\n",
      "[TRN] epoch = 565, cost = 8.83e-01, |grad| = 8.95e-02, acc = 8.43e-01 (1.26s)\n",
      "[VAL] epoch = 565, data_cost = 7.17e-01, cost = 1.06e+00, acc = 7.98e-01 (0.28s)\n",
      "[TST] epoch = 565, cost = 1.02e+00, acc = 8.23e-01 (0.28s)\n",
      "[TRN] epoch = 570, cost = 7.83e-01, |grad| = 7.94e-02, acc = 8.86e-01 (1.29s)\n",
      "[VAL] epoch = 570, data_cost = 7.14e-01, cost = 1.06e+00, acc = 7.98e-01 (0.28s)\n",
      "[TST] epoch = 570, cost = 1.02e+00, acc = 8.25e-01 (0.28s)\n",
      "[TRN] epoch = 575, cost = 7.82e-01, |grad| = 8.39e-02, acc = 8.64e-01 (1.27s)\n",
      "[VAL] epoch = 575, data_cost = 7.13e-01, cost = 1.06e+00, acc = 7.96e-01 (0.28s)\n",
      "[TST] epoch = 575, cost = 1.02e+00, acc = 8.26e-01 (0.28s)\n",
      "[TRN] epoch = 580, cost = 7.60e-01, |grad| = 7.54e-02, acc = 8.93e-01 (1.29s)\n",
      "[VAL] epoch = 580, data_cost = 7.10e-01, cost = 1.06e+00, acc = 7.96e-01 (0.28s)\n",
      "[TST] epoch = 580, cost = 1.02e+00, acc = 8.28e-01 (0.28s)\n",
      "[TRN] epoch = 585, cost = 8.36e-01, |grad| = 8.30e-02, acc = 8.57e-01 (1.25s)\n",
      "[VAL] epoch = 585, data_cost = 7.09e-01, cost = 1.06e+00, acc = 7.96e-01 (0.27s)\n",
      "[TST] epoch = 585, cost = 1.02e+00, acc = 8.31e-01 (0.26s)\n",
      "[TRN] epoch = 590, cost = 8.49e-01, |grad| = 8.35e-02, acc = 8.57e-01 (1.26s)\n",
      "[VAL] epoch = 590, data_cost = 7.08e-01, cost = 1.06e+00, acc = 7.98e-01 (0.27s)\n",
      "[TST] epoch = 590, cost = 1.02e+00, acc = 8.29e-01 (0.26s)\n",
      "[TRN] epoch = 595, cost = 8.64e-01, |grad| = 1.20e-01, acc = 8.29e-01 (1.29s)\n",
      "[VAL] epoch = 595, data_cost = 7.06e-01, cost = 1.06e+00, acc = 7.96e-01 (0.28s)\n",
      "[TST] epoch = 595, cost = 1.01e+00, acc = 8.31e-01 (0.28s)\n",
      "[TRN] epoch = 600, cost = 8.88e-01, |grad| = 8.68e-02, acc = 8.43e-01 (1.28s)\n",
      "[VAL] epoch = 600, data_cost = 7.07e-01, cost = 1.06e+00, acc = 7.96e-01 (0.28s)\n",
      "[TST] epoch = 600, cost = 1.01e+00, acc = 8.31e-01 (0.27s)\n",
      "[TRN] epoch = 605, cost = 7.23e-01, |grad| = 1.34e-01, acc = 9.29e-01 (1.32s)\n",
      "[VAL] epoch = 605, data_cost = 7.12e-01, cost = 1.06e+00, acc = 7.92e-01 (0.27s)\n",
      "[TST] epoch = 605, cost = 1.02e+00, acc = 8.28e-01 (0.27s)\n",
      "[TRN] epoch = 610, cost = 8.20e-01, |grad| = 9.37e-02, acc = 8.57e-01 (1.22s)\n",
      "[VAL] epoch = 610, data_cost = 7.12e-01, cost = 1.06e+00, acc = 7.98e-01 (0.28s)\n",
      "[TST] epoch = 610, cost = 1.02e+00, acc = 8.29e-01 (0.27s)\n",
      "[TRN] epoch = 615, cost = 8.10e-01, |grad| = 8.89e-02, acc = 8.50e-01 (1.23s)\n",
      "[VAL] epoch = 615, data_cost = 7.13e-01, cost = 1.07e+00, acc = 7.98e-01 (0.26s)\n",
      "[TST] epoch = 615, cost = 1.02e+00, acc = 8.26e-01 (0.27s)\n",
      "[TRN] epoch = 620, cost = 8.35e-01, |grad| = 1.33e-01, acc = 8.64e-01 (1.24s)\n",
      "[VAL] epoch = 620, data_cost = 7.13e-01, cost = 1.07e+00, acc = 7.94e-01 (0.27s)\n",
      "[TST] epoch = 620, cost = 1.02e+00, acc = 8.26e-01 (0.28s)\n",
      "[TRN] epoch = 625, cost = 7.47e-01, |grad| = 1.05e-01, acc = 8.93e-01 (1.27s)\n",
      "[VAL] epoch = 625, data_cost = 7.07e-01, cost = 1.06e+00, acc = 7.96e-01 (0.27s)\n",
      "[TST] epoch = 625, cost = 1.01e+00, acc = 8.27e-01 (0.27s)\n",
      "[TRN] epoch = 630, cost = 8.93e-01, |grad| = 1.15e-01, acc = 8.21e-01 (1.28s)\n",
      "[VAL] epoch = 630, data_cost = 7.04e-01, cost = 1.06e+00, acc = 8.00e-01 (0.28s)\n",
      "[TST] epoch = 630, cost = 1.01e+00, acc = 8.26e-01 (0.27s)\n",
      "[TRN] epoch = 635, cost = 8.37e-01, |grad| = 1.04e-01, acc = 8.43e-01 (1.26s)\n",
      "[VAL] epoch = 635, data_cost = 7.11e-01, cost = 1.06e+00, acc = 7.98e-01 (0.28s)\n",
      "[TST] epoch = 635, cost = 1.02e+00, acc = 8.25e-01 (0.26s)\n",
      "[TRN] epoch = 640, cost = 7.28e-01, |grad| = 8.19e-02, acc = 9.00e-01 (1.28s)\n",
      "[VAL] epoch = 640, data_cost = 7.14e-01, cost = 1.07e+00, acc = 7.94e-01 (0.28s)\n",
      "[TST] epoch = 640, cost = 1.02e+00, acc = 8.25e-01 (0.27s)\n",
      "[TRN] epoch = 645, cost = 7.27e-01, |grad| = 9.78e-02, acc = 9.29e-01 (1.29s)\n",
      "[VAL] epoch = 645, data_cost = 7.11e-01, cost = 1.06e+00, acc = 7.96e-01 (0.27s)\n",
      "[TST] epoch = 645, cost = 1.02e+00, acc = 8.26e-01 (0.28s)\n",
      "[TRN] epoch = 650, cost = 8.23e-01, |grad| = 7.09e-02, acc = 8.64e-01 (1.25s)\n",
      "[VAL] epoch = 650, data_cost = 7.08e-01, cost = 1.06e+00, acc = 7.98e-01 (0.28s)\n",
      "[TST] epoch = 650, cost = 1.02e+00, acc = 8.26e-01 (0.27s)\n",
      "[TRN] epoch = 655, cost = 8.28e-01, |grad| = 9.88e-02, acc = 8.71e-01 (1.26s)\n",
      "[VAL] epoch = 655, data_cost = 7.11e-01, cost = 1.07e+00, acc = 7.96e-01 (0.28s)\n",
      "[TST] epoch = 655, cost = 1.02e+00, acc = 8.25e-01 (0.27s)\n",
      "[TRN] epoch = 660, cost = 7.61e-01, |grad| = 8.78e-02, acc = 8.50e-01 (1.29s)\n",
      "[VAL] epoch = 660, data_cost = 7.14e-01, cost = 1.07e+00, acc = 8.00e-01 (0.27s)\n",
      "[TST] epoch = 660, cost = 1.03e+00, acc = 8.27e-01 (0.27s)\n",
      "[TRN] epoch = 665, cost = 9.23e-01, |grad| = 1.05e-01, acc = 8.00e-01 (1.28s)\n",
      "[VAL] epoch = 665, data_cost = 7.16e-01, cost = 1.07e+00, acc = 8.02e-01 (0.26s)\n",
      "[TST] epoch = 665, cost = 1.03e+00, acc = 8.27e-01 (0.26s)\n",
      "[TRN] epoch = 670, cost = 8.30e-01, |grad| = 1.22e-01, acc = 8.57e-01 (1.26s)\n",
      "[VAL] epoch = 670, data_cost = 7.16e-01, cost = 1.07e+00, acc = 8.04e-01 (0.28s)\n",
      "[TST] epoch = 670, cost = 1.03e+00, acc = 8.24e-01 (0.29s)\n",
      "[TRN] epoch = 675, cost = 7.48e-01, |grad| = 1.06e-01, acc = 9.14e-01 (1.25s)\n",
      "[VAL] epoch = 675, data_cost = 7.12e-01, cost = 1.07e+00, acc = 8.02e-01 (0.27s)\n",
      "[TST] epoch = 675, cost = 1.02e+00, acc = 8.25e-01 (0.27s)\n",
      "[TRN] epoch = 680, cost = 8.26e-01, |grad| = 1.02e-01, acc = 8.50e-01 (1.36s)\n",
      "[VAL] epoch = 680, data_cost = 7.12e-01, cost = 1.07e+00, acc = 8.00e-01 (0.28s)\n",
      "[TST] epoch = 680, cost = 1.02e+00, acc = 8.24e-01 (0.28s)\n",
      "[TRN] epoch = 685, cost = 9.01e-01, |grad| = 9.95e-02, acc = 8.14e-01 (1.30s)\n",
      "[VAL] epoch = 685, data_cost = 7.14e-01, cost = 1.07e+00, acc = 7.98e-01 (0.27s)\n",
      "[TST] epoch = 685, cost = 1.02e+00, acc = 8.23e-01 (0.28s)\n",
      "[TRN] epoch = 690, cost = 7.35e-01, |grad| = 8.45e-02, acc = 9.07e-01 (1.31s)\n",
      "[VAL] epoch = 690, data_cost = 7.17e-01, cost = 1.07e+00, acc = 7.96e-01 (0.26s)\n",
      "[TST] epoch = 690, cost = 1.03e+00, acc = 8.20e-01 (0.28s)\n",
      "[TRN] epoch = 695, cost = 8.99e-01, |grad| = 1.05e-01, acc = 8.29e-01 (1.25s)\n",
      "[VAL] epoch = 695, data_cost = 7.20e-01, cost = 1.07e+00, acc = 7.94e-01 (0.27s)\n",
      "[TST] epoch = 695, cost = 1.03e+00, acc = 8.18e-01 (0.28s)\n",
      "[TRN] epoch = 700, cost = 8.79e-01, |grad| = 9.49e-02, acc = 8.00e-01 (1.28s)\n",
      "[VAL] epoch = 700, data_cost = 7.23e-01, cost = 1.08e+00, acc = 7.92e-01 (0.26s)\n",
      "[TST] epoch = 700, cost = 1.03e+00, acc = 8.17e-01 (0.28s)\n",
      "[TRN] epoch = 705, cost = 7.93e-01, |grad| = 8.35e-02, acc = 8.64e-01 (1.21s)\n",
      "[VAL] epoch = 705, data_cost = 7.24e-01, cost = 1.08e+00, acc = 7.96e-01 (0.28s)\n",
      "[TST] epoch = 705, cost = 1.03e+00, acc = 8.17e-01 (0.27s)\n",
      "[TRN] epoch = 710, cost = 9.05e-01, |grad| = 1.10e-01, acc = 8.36e-01 (1.32s)\n",
      "[VAL] epoch = 710, data_cost = 7.18e-01, cost = 1.07e+00, acc = 7.96e-01 (0.27s)\n",
      "[TST] epoch = 710, cost = 1.03e+00, acc = 8.20e-01 (0.28s)\n",
      "[TRN] epoch = 715, cost = 8.57e-01, |grad| = 8.38e-02, acc = 8.64e-01 (1.27s)\n",
      "[VAL] epoch = 715, data_cost = 7.10e-01, cost = 1.07e+00, acc = 7.98e-01 (0.27s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TST] epoch = 715, cost = 1.02e+00, acc = 8.25e-01 (0.26s)\n",
      "[TRN] epoch = 720, cost = 8.20e-01, |grad| = 1.04e-01, acc = 8.79e-01 (1.27s)\n",
      "[VAL] epoch = 720, data_cost = 7.10e-01, cost = 1.07e+00, acc = 7.98e-01 (0.28s)\n",
      "[TST] epoch = 720, cost = 1.02e+00, acc = 8.27e-01 (0.26s)\n",
      "[TRN] epoch = 725, cost = 8.52e-01, |grad| = 7.83e-02, acc = 8.36e-01 (1.22s)\n",
      "[VAL] epoch = 725, data_cost = 7.11e-01, cost = 1.07e+00, acc = 8.00e-01 (0.28s)\n",
      "[TST] epoch = 725, cost = 1.02e+00, acc = 8.28e-01 (0.26s)\n",
      "[TRN] epoch = 730, cost = 8.47e-01, |grad| = 1.06e-01, acc = 8.57e-01 (1.27s)\n",
      "[VAL] epoch = 730, data_cost = 7.15e-01, cost = 1.07e+00, acc = 7.96e-01 (0.28s)\n",
      "[TST] epoch = 730, cost = 1.03e+00, acc = 8.22e-01 (0.27s)\n",
      "[TRN] epoch = 735, cost = 8.14e-01, |grad| = 1.21e-01, acc = 8.79e-01 (1.26s)\n",
      "[VAL] epoch = 735, data_cost = 7.20e-01, cost = 1.08e+00, acc = 7.96e-01 (0.28s)\n",
      "[TST] epoch = 735, cost = 1.03e+00, acc = 8.22e-01 (0.28s)\n",
      "[TRN] epoch = 740, cost = 9.17e-01, |grad| = 9.68e-02, acc = 8.07e-01 (1.26s)\n",
      "[VAL] epoch = 740, data_cost = 7.22e-01, cost = 1.08e+00, acc = 8.00e-01 (0.28s)\n",
      "[TST] epoch = 740, cost = 1.03e+00, acc = 8.20e-01 (0.27s)\n",
      "[TRN] epoch = 745, cost = 8.56e-01, |grad| = 1.25e-01, acc = 8.71e-01 (1.26s)\n",
      "[VAL] epoch = 745, data_cost = 7.21e-01, cost = 1.08e+00, acc = 8.00e-01 (0.28s)\n",
      "[TST] epoch = 745, cost = 1.03e+00, acc = 8.22e-01 (0.27s)\n",
      "[TRN] epoch = 750, cost = 8.25e-01, |grad| = 8.15e-02, acc = 8.79e-01 (1.30s)\n",
      "[VAL] epoch = 750, data_cost = 7.15e-01, cost = 1.08e+00, acc = 8.00e-01 (0.28s)\n",
      "[TST] epoch = 750, cost = 1.03e+00, acc = 8.25e-01 (0.28s)\n",
      "[TRN] epoch = 755, cost = 8.75e-01, |grad| = 9.89e-02, acc = 8.43e-01 (1.26s)\n",
      "[VAL] epoch = 755, data_cost = 7.15e-01, cost = 1.08e+00, acc = 8.00e-01 (0.28s)\n",
      "[TST] epoch = 755, cost = 1.03e+00, acc = 8.24e-01 (0.27s)\n",
      "[TRN] epoch = 760, cost = 8.44e-01, |grad| = 1.07e-01, acc = 8.14e-01 (1.23s)\n",
      "[VAL] epoch = 760, data_cost = 7.15e-01, cost = 1.08e+00, acc = 7.98e-01 (0.26s)\n",
      "[TST] epoch = 760, cost = 1.03e+00, acc = 8.24e-01 (0.26s)\n",
      "[TRN] epoch = 765, cost = 8.49e-01, |grad| = 1.33e-01, acc = 8.50e-01 (1.25s)\n",
      "[VAL] epoch = 765, data_cost = 7.16e-01, cost = 1.08e+00, acc = 8.00e-01 (0.28s)\n",
      "[TST] epoch = 765, cost = 1.03e+00, acc = 8.24e-01 (0.27s)\n",
      "[TRN] epoch = 770, cost = 7.44e-01, |grad| = 7.99e-02, acc = 9.14e-01 (1.27s)\n",
      "[VAL] epoch = 770, data_cost = 7.14e-01, cost = 1.08e+00, acc = 8.00e-01 (0.28s)\n",
      "[TST] epoch = 770, cost = 1.03e+00, acc = 8.25e-01 (0.27s)\n",
      "[TRN] epoch = 775, cost = 8.65e-01, |grad| = 1.01e-01, acc = 8.29e-01 (1.30s)\n",
      "[VAL] epoch = 775, data_cost = 7.10e-01, cost = 1.07e+00, acc = 8.00e-01 (0.27s)\n",
      "[TST] epoch = 775, cost = 1.02e+00, acc = 8.25e-01 (0.28s)\n",
      "[TRN] epoch = 780, cost = 8.03e-01, |grad| = 9.27e-02, acc = 8.64e-01 (1.29s)\n",
      "[VAL] epoch = 780, data_cost = 7.07e-01, cost = 1.07e+00, acc = 8.00e-01 (0.28s)\n",
      "[TST] epoch = 780, cost = 1.02e+00, acc = 8.26e-01 (0.26s)\n",
      "[TRN] epoch = 785, cost = 8.38e-01, |grad| = 9.19e-02, acc = 8.57e-01 (1.25s)\n",
      "[VAL] epoch = 785, data_cost = 7.06e-01, cost = 1.07e+00, acc = 8.04e-01 (0.27s)\n",
      "[TST] epoch = 785, cost = 1.02e+00, acc = 8.23e-01 (0.26s)\n",
      "[TRN] epoch = 790, cost = 7.77e-01, |grad| = 8.62e-02, acc = 9.14e-01 (1.25s)\n",
      "[VAL] epoch = 790, data_cost = 7.06e-01, cost = 1.07e+00, acc = 8.04e-01 (0.26s)\n",
      "[TST] epoch = 790, cost = 1.02e+00, acc = 8.24e-01 (0.28s)\n",
      "[TRN] epoch = 795, cost = 7.50e-01, |grad| = 1.15e-01, acc = 9.00e-01 (1.26s)\n",
      "[VAL] epoch = 795, data_cost = 7.02e-01, cost = 1.06e+00, acc = 8.02e-01 (0.28s)\n",
      "[TST] epoch = 795, cost = 1.02e+00, acc = 8.23e-01 (0.27s)\n",
      "[TRN] epoch = 800, cost = 7.92e-01, |grad| = 1.13e-01, acc = 8.64e-01 (1.29s)\n",
      "[VAL] epoch = 800, data_cost = 7.05e-01, cost = 1.07e+00, acc = 8.00e-01 (0.28s)\n",
      "[TST] epoch = 800, cost = 1.02e+00, acc = 8.22e-01 (0.27s)\n",
      "[TRN] epoch = 805, cost = 8.11e-01, |grad| = 9.02e-02, acc = 8.57e-01 (1.34s)\n",
      "[VAL] epoch = 805, data_cost = 7.10e-01, cost = 1.07e+00, acc = 7.96e-01 (0.26s)\n",
      "[TST] epoch = 805, cost = 1.03e+00, acc = 8.23e-01 (0.27s)\n",
      "[TRN] epoch = 810, cost = 8.08e-01, |grad| = 9.79e-02, acc = 8.64e-01 (1.29s)\n",
      "[VAL] epoch = 810, data_cost = 7.12e-01, cost = 1.07e+00, acc = 7.98e-01 (0.28s)\n",
      "[TST] epoch = 810, cost = 1.03e+00, acc = 8.21e-01 (0.28s)\n",
      "[TRN] epoch = 815, cost = 9.25e-01, |grad| = 1.04e-01, acc = 8.79e-01 (1.23s)\n",
      "[VAL] epoch = 815, data_cost = 7.10e-01, cost = 1.07e+00, acc = 7.96e-01 (0.28s)\n",
      "[TST] epoch = 815, cost = 1.03e+00, acc = 8.20e-01 (0.28s)\n",
      "[TRN] epoch = 820, cost = 8.38e-01, |grad| = 8.98e-02, acc = 8.57e-01 (1.26s)\n",
      "[VAL] epoch = 820, data_cost = 7.06e-01, cost = 1.07e+00, acc = 8.00e-01 (0.26s)\n",
      "[TST] epoch = 820, cost = 1.02e+00, acc = 8.21e-01 (0.28s)\n",
      "[TRN] epoch = 825, cost = 8.70e-01, |grad| = 1.23e-01, acc = 8.50e-01 (1.24s)\n",
      "[VAL] epoch = 825, data_cost = 7.04e-01, cost = 1.07e+00, acc = 8.00e-01 (0.28s)\n",
      "[TST] epoch = 825, cost = 1.02e+00, acc = 8.19e-01 (0.28s)\n",
      "[TRN] epoch = 830, cost = 7.87e-01, |grad| = 8.23e-02, acc = 8.79e-01 (1.22s)\n",
      "[VAL] epoch = 830, data_cost = 7.10e-01, cost = 1.07e+00, acc = 7.96e-01 (0.28s)\n",
      "[TST] epoch = 830, cost = 1.03e+00, acc = 8.17e-01 (0.26s)\n",
      "[TRN] epoch = 835, cost = 8.20e-01, |grad| = 8.43e-02, acc = 8.50e-01 (1.30s)\n",
      "[VAL] epoch = 835, data_cost = 7.15e-01, cost = 1.08e+00, acc = 7.96e-01 (0.28s)\n",
      "[TST] epoch = 835, cost = 1.03e+00, acc = 8.20e-01 (0.28s)\n",
      "[TRN] epoch = 840, cost = 8.06e-01, |grad| = 1.08e-01, acc = 8.71e-01 (1.29s)\n",
      "[VAL] epoch = 840, data_cost = 7.17e-01, cost = 1.08e+00, acc = 7.98e-01 (0.26s)\n",
      "[TST] epoch = 840, cost = 1.03e+00, acc = 8.16e-01 (0.28s)\n",
      "[TRN] epoch = 845, cost = 7.61e-01, |grad| = 9.08e-02, acc = 8.86e-01 (1.28s)\n",
      "[VAL] epoch = 845, data_cost = 7.16e-01, cost = 1.08e+00, acc = 7.96e-01 (0.28s)\n",
      "[TST] epoch = 845, cost = 1.03e+00, acc = 8.24e-01 (0.28s)\n",
      "[TRN] epoch = 850, cost = 8.85e-01, |grad| = 1.12e-01, acc = 8.29e-01 (1.27s)\n",
      "[VAL] epoch = 850, data_cost = 7.10e-01, cost = 1.07e+00, acc = 7.96e-01 (0.28s)\n",
      "[TST] epoch = 850, cost = 1.03e+00, acc = 8.23e-01 (0.27s)\n",
      "[TRN] epoch = 855, cost = 8.64e-01, |grad| = 1.00e-01, acc = 8.57e-01 (1.32s)\n",
      "[VAL] epoch = 855, data_cost = 7.05e-01, cost = 1.07e+00, acc = 7.98e-01 (0.29s)\n",
      "[TST] epoch = 855, cost = 1.02e+00, acc = 8.23e-01 (0.28s)\n",
      "[TRN] epoch = 860, cost = 7.85e-01, |grad| = 9.59e-02, acc = 8.79e-01 (1.26s)\n",
      "[VAL] epoch = 860, data_cost = 7.02e-01, cost = 1.06e+00, acc = 7.96e-01 (0.29s)\n",
      "[TST] epoch = 860, cost = 1.02e+00, acc = 8.24e-01 (0.30s)\n",
      "[TRN] epoch = 865, cost = 7.76e-01, |grad| = 8.12e-02, acc = 8.86e-01 (1.26s)\n",
      "[VAL] epoch = 865, data_cost = 7.03e-01, cost = 1.07e+00, acc = 8.00e-01 (0.28s)\n",
      "[TST] epoch = 865, cost = 1.02e+00, acc = 8.25e-01 (0.26s)\n",
      "[TRN] epoch = 870, cost = 8.31e-01, |grad| = 8.22e-02, acc = 8.79e-01 (1.34s)\n",
      "[VAL] epoch = 870, data_cost = 7.10e-01, cost = 1.07e+00, acc = 7.98e-01 (0.29s)\n",
      "[TST] epoch = 870, cost = 1.03e+00, acc = 8.23e-01 (0.28s)\n",
      "[TRN] epoch = 875, cost = 8.23e-01, |grad| = 8.15e-02, acc = 8.43e-01 (1.24s)\n",
      "[VAL] epoch = 875, data_cost = 7.16e-01, cost = 1.08e+00, acc = 7.92e-01 (0.28s)\n",
      "[TST] epoch = 875, cost = 1.03e+00, acc = 8.23e-01 (0.28s)\n",
      "[TRN] epoch = 880, cost = 8.97e-01, |grad| = 8.98e-02, acc = 8.07e-01 (1.21s)\n",
      "[VAL] epoch = 880, data_cost = 7.18e-01, cost = 1.08e+00, acc = 7.90e-01 (0.28s)\n",
      "[TST] epoch = 880, cost = 1.04e+00, acc = 8.24e-01 (0.26s)\n",
      "[TRN] epoch = 885, cost = 9.24e-01, |grad| = 1.01e-01, acc = 8.50e-01 (1.25s)\n",
      "[VAL] epoch = 885, data_cost = 7.19e-01, cost = 1.08e+00, acc = 7.90e-01 (0.26s)\n",
      "[TST] epoch = 885, cost = 1.04e+00, acc = 8.26e-01 (0.27s)\n",
      "[TRN] epoch = 890, cost = 9.78e-01, |grad| = 1.14e-01, acc = 8.00e-01 (1.32s)\n",
      "[VAL] epoch = 890, data_cost = 7.16e-01, cost = 1.08e+00, acc = 7.98e-01 (0.29s)\n",
      "[TST] epoch = 890, cost = 1.03e+00, acc = 8.26e-01 (0.28s)\n",
      "[TRN] epoch = 895, cost = 7.98e-01, |grad| = 7.07e-02, acc = 9.00e-01 (1.29s)\n",
      "[VAL] epoch = 895, data_cost = 7.14e-01, cost = 1.08e+00, acc = 7.96e-01 (0.28s)\n",
      "[TST] epoch = 895, cost = 1.03e+00, acc = 8.22e-01 (0.28s)\n",
      "[TRN] epoch = 900, cost = 8.79e-01, |grad| = 1.09e-01, acc = 8.36e-01 (1.29s)\n",
      "[VAL] epoch = 900, data_cost = 7.17e-01, cost = 1.08e+00, acc = 7.94e-01 (0.26s)\n",
      "[TST] epoch = 900, cost = 1.04e+00, acc = 8.25e-01 (0.27s)\n",
      "[TRN] epoch = 905, cost = 8.07e-01, |grad| = 8.27e-02, acc = 8.50e-01 (1.29s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] epoch = 905, data_cost = 7.19e-01, cost = 1.08e+00, acc = 7.94e-01 (0.27s)\n",
      "[TST] epoch = 905, cost = 1.04e+00, acc = 8.25e-01 (0.31s)\n",
      "[TRN] epoch = 910, cost = 7.68e-01, |grad| = 8.10e-02, acc = 8.64e-01 (1.25s)\n",
      "[VAL] epoch = 910, data_cost = 7.20e-01, cost = 1.08e+00, acc = 7.98e-01 (0.27s)\n",
      "[TST] epoch = 910, cost = 1.04e+00, acc = 8.20e-01 (0.26s)\n",
      "[TRN] epoch = 915, cost = 7.56e-01, |grad| = 8.01e-02, acc = 8.79e-01 (1.27s)\n",
      "[VAL] epoch = 915, data_cost = 7.18e-01, cost = 1.08e+00, acc = 7.96e-01 (0.29s)\n",
      "[TST] epoch = 915, cost = 1.04e+00, acc = 8.20e-01 (0.28s)\n",
      "[TRN] epoch = 920, cost = 7.83e-01, |grad| = 1.07e-01, acc = 8.64e-01 (1.32s)\n",
      "[VAL] epoch = 920, data_cost = 7.14e-01, cost = 1.08e+00, acc = 7.98e-01 (0.28s)\n",
      "[TST] epoch = 920, cost = 1.03e+00, acc = 8.22e-01 (0.27s)\n",
      "[TRN] epoch = 925, cost = 7.70e-01, |grad| = 9.95e-02, acc = 9.07e-01 (1.25s)\n",
      "[VAL] epoch = 925, data_cost = 7.11e-01, cost = 1.08e+00, acc = 7.98e-01 (0.26s)\n",
      "[TST] epoch = 925, cost = 1.03e+00, acc = 8.21e-01 (0.28s)\n",
      "[TRN] epoch = 930, cost = 8.40e-01, |grad| = 8.86e-02, acc = 8.93e-01 (1.26s)\n",
      "[VAL] epoch = 930, data_cost = 7.06e-01, cost = 1.07e+00, acc = 7.96e-01 (0.28s)\n",
      "[TST] epoch = 930, cost = 1.03e+00, acc = 8.23e-01 (0.28s)\n",
      "[TRN] epoch = 935, cost = 8.05e-01, |grad| = 8.21e-02, acc = 8.86e-01 (1.31s)\n",
      "[VAL] epoch = 935, data_cost = 7.04e-01, cost = 1.07e+00, acc = 7.98e-01 (0.28s)\n",
      "[TST] epoch = 935, cost = 1.02e+00, acc = 8.24e-01 (0.29s)\n",
      "[TRN] epoch = 940, cost = 8.19e-01, |grad| = 1.30e-01, acc = 8.64e-01 (1.30s)\n",
      "[VAL] epoch = 940, data_cost = 7.06e-01, cost = 1.07e+00, acc = 7.98e-01 (0.26s)\n",
      "[TST] epoch = 940, cost = 1.03e+00, acc = 8.24e-01 (0.26s)\n",
      "[TRN] epoch = 945, cost = 8.34e-01, |grad| = 1.01e-01, acc = 8.64e-01 (1.32s)\n",
      "[VAL] epoch = 945, data_cost = 7.07e-01, cost = 1.07e+00, acc = 7.96e-01 (0.28s)\n",
      "[TST] epoch = 945, cost = 1.03e+00, acc = 8.24e-01 (0.28s)\n",
      "[TRN] epoch = 950, cost = 7.88e-01, |grad| = 9.22e-02, acc = 8.86e-01 (1.31s)\n",
      "[VAL] epoch = 950, data_cost = 7.01e-01, cost = 1.06e+00, acc = 7.98e-01 (0.28s)\n",
      "[TST] epoch = 950, cost = 1.02e+00, acc = 8.22e-01 (0.27s)\n",
      "[TRN] epoch = 955, cost = 7.90e-01, |grad| = 8.67e-02, acc = 8.79e-01 (1.24s)\n",
      "[VAL] epoch = 955, data_cost = 6.99e-01, cost = 1.06e+00, acc = 8.02e-01 (0.28s)\n",
      "[TST] epoch = 955, cost = 1.02e+00, acc = 8.23e-01 (0.27s)\n",
      "[TRN] epoch = 960, cost = 8.38e-01, |grad| = 8.66e-02, acc = 8.50e-01 (1.28s)\n",
      "[VAL] epoch = 960, data_cost = 6.96e-01, cost = 1.06e+00, acc = 8.06e-01 (0.28s)\n",
      "[TST] epoch = 960, cost = 1.02e+00, acc = 8.22e-01 (0.27s)\n",
      "[TRN] epoch = 965, cost = 7.79e-01, |grad| = 1.33e-01, acc = 8.93e-01 (1.40s)\n",
      "[VAL] epoch = 965, data_cost = 6.98e-01, cost = 1.06e+00, acc = 8.00e-01 (0.29s)\n",
      "[TST] epoch = 965, cost = 1.02e+00, acc = 8.20e-01 (0.26s)\n",
      "[TRN] epoch = 970, cost = 8.95e-01, |grad| = 1.01e-01, acc = 8.14e-01 (1.25s)\n",
      "[VAL] epoch = 970, data_cost = 7.05e-01, cost = 1.07e+00, acc = 8.00e-01 (0.28s)\n",
      "[TST] epoch = 970, cost = 1.02e+00, acc = 8.23e-01 (0.29s)\n",
      "[TRN] epoch = 975, cost = 8.35e-01, |grad| = 1.09e-01, acc = 8.57e-01 (1.23s)\n",
      "[VAL] epoch = 975, data_cost = 7.13e-01, cost = 1.08e+00, acc = 7.96e-01 (0.27s)\n",
      "[TST] epoch = 975, cost = 1.03e+00, acc = 8.24e-01 (0.27s)\n",
      "[TRN] epoch = 980, cost = 7.83e-01, |grad| = 1.09e-01, acc = 8.79e-01 (1.30s)\n",
      "[VAL] epoch = 980, data_cost = 7.22e-01, cost = 1.09e+00, acc = 7.94e-01 (0.29s)\n",
      "[TST] epoch = 980, cost = 1.04e+00, acc = 8.24e-01 (0.28s)\n",
      "[TRN] epoch = 985, cost = 7.97e-01, |grad| = 7.80e-02, acc = 8.64e-01 (1.32s)\n",
      "[VAL] epoch = 985, data_cost = 7.29e-01, cost = 1.09e+00, acc = 7.94e-01 (0.28s)\n",
      "[TST] epoch = 985, cost = 1.05e+00, acc = 8.25e-01 (0.29s)\n",
      "[TRN] epoch = 990, cost = 8.18e-01, |grad| = 8.25e-02, acc = 8.86e-01 (1.31s)\n",
      "[VAL] epoch = 990, data_cost = 7.22e-01, cost = 1.09e+00, acc = 7.96e-01 (0.28s)\n",
      "[TST] epoch = 990, cost = 1.04e+00, acc = 8.24e-01 (0.28s)\n",
      "[TRN] epoch = 995, cost = 7.77e-01, |grad| = 8.49e-02, acc = 8.93e-01 (1.37s)\n",
      "[VAL] epoch = 995, data_cost = 7.14e-01, cost = 1.08e+00, acc = 7.98e-01 (0.27s)\n",
      "[TST] epoch = 995, cost = 1.03e+00, acc = 8.24e-01 (0.28s)\n",
      "Num done: 0\n",
      "Max accuracy on test set achieved: 83.099998%\n",
      "Max suggested accuracy: 82.200003%\n",
      "Current mean: 82.200005%\n",
      "Current std: 0.000000\n"
     ]
    }
   ],
   "source": [
    "num_exp = 1 #number of times training GAT over the given dataset\n",
    "\n",
    "list_all_acc = []\n",
    "list_all_cost_val_avg  = []\n",
    "list_all_data_cost_val_avg = []\n",
    "list_all_acc_val_avg   = []\n",
    "list_all_cost_test_avg = []\n",
    "list_all_acc_test_avg  = []\n",
    "\n",
    "num_done = 0\n",
    "for seed in range(num_exp):\n",
    "    GCNN = GAT_new(A_tilde, X, Y, num_layers=2, num_hidden_feat=8, num_heads=[8,1], learning_rate=learning_rate, gamma=gamma)\n",
    "\n",
    "    cost_train_avg      = []\n",
    "    grad_norm_train_avg = []\n",
    "    acc_train_avg       = []\n",
    "    cost_test_avg       = []\n",
    "    grad_norm_test_avg  = []\n",
    "    acc_test_avg        = []\n",
    "    cost_val_avg        = []\n",
    "    data_cost_val_avg   = []\n",
    "    acc_val_avg         = []\n",
    "    iter_test           = []\n",
    "    list_training_time = list()\n",
    "\n",
    "    #Training code\n",
    "    for i in range(num_total_iter_training):\n",
    "        if (len(cost_train_avg) % val_test_interval) == 0:\n",
    "            #Print last training performance\n",
    "            if (len(cost_train_avg)>0):\n",
    "                print(\"[TRN] epoch = %03i, cost = %3.2e, |grad| = %.2e, acc = %3.2e (%03.2fs)\" % \\\n",
    "                (len(cost_train_avg), cost_train_avg[-1], grad_norm_train_avg[-1], acc_train_avg[-1], time.time() - tic))\n",
    "\n",
    "            #Validate the model\n",
    "            tic = time.time()\n",
    "            \n",
    "            feed_dict = {GCNN.idx_nodes: val_idx, GCNN.keep_prob:1.0}\n",
    "            acc_val, cost_val, data_cost_val = GCNN.session.run([GCNN.accuracy, GCNN.loss, GCNN.data_loss], feed_dict)\n",
    "            \n",
    "            data_cost_val_avg.append(data_cost_val)\n",
    "            cost_val_avg.append(cost_val)\n",
    "            acc_val_avg.append(acc_val)\n",
    "            print(\"[VAL] epoch = %03i, data_cost = %3.2e, cost = %3.2e, acc = %3.2e (%03.2fs)\" % \\\n",
    "                (len(cost_train_avg), data_cost_val_avg[-1], cost_val_avg[-1], acc_val_avg[-1],  time.time() - tic))\n",
    "\n",
    "            #Test the model\n",
    "            tic = time.time()\n",
    "            \n",
    "            feed_dict = {GCNN.idx_nodes: test_idx, GCNN.keep_prob:1.0}\n",
    "            acc_test, cost_test = GCNN.session.run([GCNN.accuracy, GCNN.loss], feed_dict)\n",
    "            \n",
    "            cost_test_avg.append(cost_test)\n",
    "            acc_test_avg.append(acc_test)\n",
    "            print(\"[TST] epoch = %03i, cost = %3.2e, acc = %3.2e (%03.2fs)\" % \\\n",
    "                (len(cost_train_avg), cost_test_avg[-1], acc_test_avg[-1],  time.time() - tic))\n",
    "            iter_test.append(len(cost_train_avg))\n",
    "\n",
    "        tic = time.time()\n",
    "\n",
    "        tic = time.time()\n",
    "        feed_dict = {GCNN.idx_nodes: train_idx, GCNN.keep_prob: 0.6}\n",
    "        \n",
    "        _, current_training_loss, norm_grad, current_acc_training = GCNN.session.run([GCNN.opt_step, GCNN.loss, GCNN.norm_grad, GCNN.accuracy], feed_dict) \n",
    "\n",
    "        #_, current_training_loss, current_acc_training = GCNN.session.run([GCNN.opt_step, GCNN.loss, GCNN.accuracy], feed_dict) \n",
    "        training_time = time.time() - tic   \n",
    "        #norm_grad = 1.0\n",
    "\n",
    "        cost_train_avg.append(current_training_loss)\n",
    "        grad_norm_train_avg.append(norm_grad)\n",
    "        acc_train_avg.append(current_acc_training)\n",
    "\n",
    "    #Compute and print statistics of the last realized experiment\n",
    "    list_all_acc.append(100*(np.asarray(acc_test_avg)[np.asarray(data_cost_val_avg)==np.min(data_cost_val_avg)]))\n",
    "    list_all_cost_val_avg.append(cost_val_avg)\n",
    "    list_all_data_cost_val_avg.append(data_cost_val_avg)\n",
    "    list_all_acc_val_avg.append(acc_val_avg)\n",
    "    list_all_cost_test_avg.append(cost_test_avg)\n",
    "    list_all_acc_test_avg.append(acc_test_avg)\n",
    "\n",
    "    print('Num done: %d' % num_done)\n",
    "    print('Max accuracy on test set achieved: %f%%' % np.max(np.asarray(acc_test_avg)*100))\n",
    "    print('Max suggested accuracy: %f%%' % (100*(np.asarray(acc_test_avg)[np.argmin(data_cost_val_avg)]),))\n",
    "    print('Current mean: %f%%' % np.mean(list_all_acc))\n",
    "    print('Current std: %f' % np.std(list_all_acc))\n",
    "\n",
    "    num_done += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yuxv7i-UFtD1",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "9-uopyk_FtD5",
    "outputId": "be277aa9-a47d-456d-ab4c-17d9e07a67e1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TwIUzSLH_um0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "GAT-final.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "nteract": {
   "version": "0.21.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
